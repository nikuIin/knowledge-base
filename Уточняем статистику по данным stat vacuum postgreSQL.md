[[postgreSQL]]

```sql
\x

select schemaname, tablename, most_common_vals, most_common_freqs
from pg_stats
where tablename = 'employee' and attname = 'department';

-[ RECORD 1 ]-----+---------------------------------------
schemaname | public
tablename | employee
most_common_vals | {sales,IT,management,accounting}
most_common_freqs | {0.5941,0.34493333,0.0502,0.010766666}
```

Воу! Оказывается, постгрес знает, какие наиболее частые значения есть в таблица `employee` в колонке `department`. Прям знает, что:

- `sales` – 59.41% записей
    
- `IT` – 34.49% записей
    
- `management` – 5.02% записей
    
- `accounting` – 1.08% записей
    

Соответственно когда мы ищем бухгалтеров, то есть `accounting`, постгрес понимает, что их немного, 1%, и тут лучше воспользоваться индексом. А вот IT аж 35% почти, тут индекс не поможет, и надо просто лопатить всю таблицу.

Соответственно, если статистики нет или она неточная, то PostgreSQL не может строить правильные планы выполнения запросов. Поэтому после массового изменения данных можно запускать `ANALYZE`, чтобы принудительно собрать статистику. Например:

```sql
analyze employee;
-- или 
vacuum analyze employee;
```

Если в плане выполнения запросов планируемое количество строк сильно отличается от реального количества строк, то часто это говорит о недостаточной статистике. Возможно, её надо собрать-обновить, то есть, запустить `analyze` или дождаться автоматического обновления процессом автовакуума, но там постгрес может решить, что пока рано обновлять аналитику по конкретной таблице, например, потому что слишком мало в ней данных изменилось, и тогда всё-таки вручную запустить будет нелишним, или возможно, уже собранную статистику надо уточнить.

Как посмотреть, когда обновлялась статистика по таблице?

```sql
select relname, last_analyze, last_autoanalyze
from pg_stat_all_tables
where relname = 'employee';

 relname | last_analyze | last_autoanalyze
----------+-------------------------------+------------------
 employee | 2025-02-25 19:37:30.082675+03 |
(1 строка)
```

Если давно или до нашего какого-то массового изменения данных — можно просто перезапустить сбор аналитики вручную с `ANALYZE`.

Ну и иногда можно уточнять статистику. По умолчанию анализатор берет 300 рандомных, то есть случайных значений из таблицы и на их основе составляет статистику. Если таблица большая и данные распределены очень неравномерно, то можно уточнять сбор статистики по этой колонке вот так:

```sql
alter table employee alter column department set statistics 1000;

analyze employee;
```

Теперь будет браться не 300 строк, а 1000 строк для анализа. Конечно, теперь дольше будет выполняться анализ и больше значений надо будет хранить в статистике, но иногда это даёт планировщику запросов больше точных данных о таблице и он начинает в каких-то отдельных случаях строить лучшие планы. Наобум уточнять везде статистику не надо, конечно. Но если вы видите, что PostgresSQL неверно оценивает количество строк в каком-то месте, но статистика собрана недавно, то для большой таблицы можно попробовать уточнить в ней статистику по нужному столбцу.